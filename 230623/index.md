# 2023-06-23

## 회귀분석

* 가변수(dummy variable)
    * 질적변수를 양적변수와 동일하게 취급할 수 있게 하는 기법
    * 0과 1을 취하는 2진 변수이다.

### 모형의 선택
* 적합이 좋은 모형
    * 모형이 주변에 있는 데이터에 어느 정도 들어맞는다는 것.
    * 잔차가 작으면 좋은 모형
* 예측이 좋은 모형
    * 미지의 데이터를 어느 정도 예측할 수 있는 모형
    * 모르는 데이터의 설명변수라도 모형이 반응변수를 정확하게 예측할 수 있다면 그것은 좋은 모형이라고 할 수 있다.
* 과적합(overfitting)
    * 설명변수를 증가시켜 적합이 좋게 할 수 있으나, 반동으로 예측 정확도가 떨어지는 현상.
    * 따라서 모형을 고를 때는 예측 정확도가 좋은 것을 고르게 된다.

#### 결정계수

* 결정계수(R-squared)
    * 0과 1 사이의 값을 취하고, 1에 가까울수록 모델은 데이터에 잘 들어맞는다 생각할 수 있다.
* 조정결정계수(adjusted R-squared)
    * 자유도조정 결정계수라고도 한다.
    * 각각의 자유도로 나누어 계산한다.
    * 총 변동의 자유도 = 회귀변동의 자유도 + 잔차변동의 자유도
* 변동
    * 총변동(total variation)
        * 관측값이 어느 정도 분산되어있는가
    * 회귀변동(regression variation)
        * 예측값이 관측값의 평균값에 대해 어느정도 분산되어 있는가
    * 잔차변동(residual variation)
        * 잔차의 산포도를 나타내는 지표
    * 총변동 = 회귀변동 + 잔차변동
* F 검정(F test)
    * 모형 전체에 수행되는 검정
    * 대립가설은 적어도 하나의 회귀계수가 0이 아니다. 이다.
    * 분산 분석(analysis of variance, ANOVA)이라고도 부른다.
        * 잔차의 분산과 모형의 분산의 비를 검정하고 있다고 해석할 수 있어서.

#### 최대로그우도와 AIC

* pmf(probability mass function)
    * 이산 확률 변수에서 특정 값에 대한 확률을 나타내는 함수
* 우도(likelihood)
    * 어떤 관측값을 얻을 확률
* 우도함수(likelihood function) as $L(p)$
    * 우도 L은 p에 대한 함수로 표현된다.
* 최우추정법(method of maximum likelihood)
    * 가장 그럴듯하다는 이유로 모수 p를 추정하는 방법
    * 제일 큰 것을 택하는 것 같다.
* 최우추정량(maximum likelihood estimator)
    * 최우추정법에 의해 추측되는 추정량
* 최우추정값(maximum likelihood estimate)
    * 이에 따른 추정값을 최우추정값이라고 한다.
* 로그우도(log-likelihood)
    * 우도에 로그를 취한 값
* 최대로그우도(maximum log-likelihood)
    * 로그우도 함수가 최대가 될 때의 로그우도 값
    * 설명변수를 늘리면 값이 증가하는 특징이 있다
    * 값이 클수록 모형의 적합도가 높다고 생각할 수 있다.
* 아카이케의 정보량 기준(Akaike's information criterion, AIC)
    * 최대로그우도를 사용하되, 설명변수를 무작정 늘려서 값을 늘릴 수 없게 한 지표
    * statsmodels에서는 `AIC = -2 * <최대로그우도> + 2 * <회귀계수의 수>`로 정의한다.
    * 값이 작을수록 모형의 예측 정확도가 좋다고 생각한다.
* 베이지안 정보 기준 (Bayesian information criterion, BIC)
    * AIC와 유사한 지표로, 표본 크기 n에 대해서도 패널티를 부가
    * 값이 작을수록 모형의 예측 정확도가 좋다고 생각한다.

### 모형의 타당성

모형의 타당성이란 '오차항들은 서로 독립이고 $N(0, σ^2)$를 따른다.'라는 가정을 만족하고 있는지 여부를 체크하는 것.

* 정규성 검정
    * 잔차가 정규분포를 따르고 있는지 확인하는 정규성 검정을 수행
    * statsmodels에서는 Omnibus 검정과 Jarque-Bera 검정이 사용된다.
    * 귀무가설은 잔차항은 정규분포를 따릅니다. 이다.
    * 왜도(skewness)
        * 분포의 좌우대칭을 측정하는 지표
        * 좌우대칭이면 0, 왼쪽으로 치우치면 0보다 크고, 오른쪽으로 치우치면 0보다 작다.
        * `stats.skew(...)`
    * 첨도(kurtosis)
        * 분포의 뾰족한 정도를 측정하는 지표
        * 정규분포이면 3, 더 뾰족하면 크고 아니면 작다.
        * `stats.kurtosis(..., fisher=False)`
* 더빈-왓슨비(Durbin-Watson ratio)
    * 다른 오차항이 서로 무상관인지 여부를 체크하는 지표이다.
    * 시계열 데이터를 다루는 경우 특히 중요하다.
    * 0부터 4의 값을 가지고, 0에 가까우면 양의 상관, 4에 가까우면 음의 상관, 2에 가까우면 무상관이라고 판단한다.
* 조건수(Cond. No.)
    * 값이 크면 다중공선성과 설명변수 사이에 강한 상관이 생겼다는 의미
* 다중공선성(multicollinearity)
    * 크면 회귀계수의 분산이 커져 모형의 예측 결과가 나빠진다고 알려져 있다.
    * 독립 변수의 일부가 다른 독립 변수의 조합으로 표현될 수 있는 경우
